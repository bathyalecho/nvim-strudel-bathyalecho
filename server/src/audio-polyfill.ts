/**
 * Audio API polyfill for Node.js
 * 
 * This module MUST be imported first, before any other modules that use Web Audio API.
 * It sets up globalThis.AudioContext and adds all the prototype methods that
 * superdough expects (like createReverb).
 * 
 * The key issue: With ESM static imports, all imports are hoisted and resolved
 * BEFORE any code executes. So we can't do:
 * 
 *   import * as nodeWebAudio from 'node-web-audio-api';
 *   Object.assign(globalThis, nodeWebAudio);  // Runs AFTER superdough is loaded!
 *   import { superdough } from 'superdough';  // Already loaded without polyfill
 * 
 * This module exports a function that sets up the polyfill, which we call
 * immediately at the top of strudel-engine.ts.
 */

import * as nodeWebAudio from 'node-web-audio-api';
import { initWorkletPolyfill } from './worklet-polyfill.js';

// Store whether we've initialized
let initialized = false;

// Track scheduled worklet disconnects for cleanup on hush
const scheduledDisconnects = new Map<any, NodeJS.Timeout>();

// Track all active worklet nodes with their end times for statistics
interface TrackedNode {
  node: any;
  name: string;
  endTime: number;
  createdAt: number;
}
const activeWorkletNodes = new Map<any, TrackedNode>();

/**
 * Get statistics about active audio worklet nodes
 */
export function getWorkletStats(): {
  total: number;
  pending: number;  // Nodes waiting to be disconnected
  byType: Record<string, number>;
} {
  const now = Date.now();
  const byType: Record<string, number> = {};
  let pending = 0;
  
  for (const [node, info] of activeWorkletNodes) {
    byType[info.name] = (byType[info.name] || 0) + 1;
    if (scheduledDisconnects.has(node)) {
      pending++;
    }
  }
  
  return {
    total: activeWorkletNodes.size,
    pending,
    byType,
  };
}

/**
 * Get count of active nodes that haven't finished yet
 * @param ctx AudioContext to check against
 */
export function getActiveNodeCount(ctx?: any): number {
  if (!ctx) return activeWorkletNodes.size;
  
  const currentTime = ctx.currentTime;
  let active = 0;
  
  for (const [_, info] of activeWorkletNodes) {
    if (info.endTime > currentTime) {
      active++;
    }
  }
  
  return active;
}

/**
 * Wait for all tracked worklet nodes to finish (or timeout)
 * This is useful for glitch-free context transitions
 * @param ctx AudioContext to check against
 * @param maxWaitMs Maximum time to wait in milliseconds (default: 5000)
 * @returns Promise that resolves when all nodes are done or timeout reached
 */
export async function waitForNodesToFinish(ctx: any, maxWaitMs = 5000): Promise<{ waited: number; remaining: number }> {
  const startTime = Date.now();
  
  // Find the latest end time among all tracked nodes
  let latestEnd = 0;
  const currentTime = ctx.currentTime;
  
  for (const [_, info] of activeWorkletNodes) {
    if (info.endTime > currentTime) {
      latestEnd = Math.max(latestEnd, info.endTime);
    }
  }
  
  if (latestEnd <= currentTime) {
    // All nodes already finished
    return { waited: 0, remaining: 0 };
  }
  
  // Calculate how long to wait (audio time to real time, plus buffer)
  const waitTimeMs = Math.min((latestEnd - currentTime) * 1000 + 200, maxWaitMs);
  
  await new Promise(resolve => setTimeout(resolve, waitTimeMs));
  
  const remaining = getActiveNodeCount(ctx);
  return { 
    waited: Date.now() - startTime, 
    remaining 
  };
}

/**
 * Cancel all scheduled worklet disconnects (for hush/stop)
 */
export function cancelScheduledDisconnects(): void {
  for (const [node, timeout] of scheduledDisconnects) {
    clearTimeout(timeout);
    try {
      node.disconnect();
    } catch {
      // Already disconnected
    }
  }
  scheduledDisconnects.clear();
  activeWorkletNodes.clear();
}

/**
 * Initialize the Web Audio API polyfill for Node.js
 * This adds AudioContext and related classes to globalThis,
 * and patches AudioContext.prototype with methods superdough expects.
 */
export function initAudioPolyfill(): void {
  if (initialized) return;
  initialized = true;

  // Add all node-web-audio-api exports to globalThis
  Object.assign(globalThis, nodeWebAudio);

  // Wrap AudioContext to use 'playback' latency hint by default on Linux
  // This prevents audio glitches/underruns with ALSA backend
  // See: https://github.com/niccolorosato/node-web-audio-api#audio-backend-and-latency
  const OriginalAudioContext = (globalThis as any).AudioContext;
  (globalThis as any).AudioContext = class AudioContextWrapper extends OriginalAudioContext {
    constructor(options?: AudioContextOptions) {
      // Default to 'playback' latency hint on Linux for stable audio
      // Users can override with WEB_AUDIO_LATENCY env var or explicit option
      const defaultOptions: AudioContextOptions = {
        latencyHint: process.env.WEB_AUDIO_LATENCY as AudioContextLatencyCategory || 'playback',
        ...options,
      };
      super(defaultOptions);
      console.log(`[audio-polyfill] AudioContext created with latencyHint: ${defaultOptions.latencyHint}`);
    }
  };

  // Add a minimal `window` object for superdough code that expects it
  // (e.g., reverbGen.mjs assigns to window.filterNode, dspworklet.mjs adds event listener)
  if (typeof (globalThis as any).window === 'undefined') {
    (globalThis as any).window = {
      ...globalThis,
      addEventListener: () => {},
      removeEventListener: () => {},
      postMessage: () => {},
    };
  } else if (!(globalThis as any).window.addEventListener) {
    // If window exists but doesn't have addEventListener (we set window = globalThis)
    (globalThis as any).window.addEventListener = () => {};
    (globalThis as any).window.removeEventListener = () => {};
    (globalThis as any).window.postMessage = () => {};
  }

  // Add a minimal `document` object for @strudel/core that checks for mousemove
  // This is a stub that does nothing - we don't have a real DOM in Node.js
  if (typeof (globalThis as any).document === 'undefined') {
    (globalThis as any).document = {
      addEventListener: () => {},
      removeEventListener: () => {},
      dispatchEvent: () => true,
      createElement: () => ({}),
      body: {},
      head: {},
    };
  }

  // Add CustomEvent for @strudel/core event dispatching
  if (typeof (globalThis as any).CustomEvent === 'undefined') {
    (globalThis as any).CustomEvent = class CustomEvent extends Event {
      detail: any;
      constructor(type: string, options?: { detail?: any }) {
        super(type);
        this.detail = options?.detail;
      }
    };
  }

  console.log('[audio-polyfill] Web Audio API polyfilled for Node.js');

  // Now manually add the prototype methods that superdough's reverb.mjs adds
  // (since reverb.mjs checks for AudioContext at module load time, which happens
  // before our polyfill runs due to ESM import hoisting)
  
  const AudioContext = (globalThis as any).AudioContext;
  if (!AudioContext) {
    console.error('[audio-polyfill] AudioContext not available after polyfill!');
    return;
  }

  // Add adjustLength method (from superdough/reverb.mjs)
  if (!AudioContext.prototype.adjustLength) {
    AudioContext.prototype.adjustLength = function(
      duration: number,
      buffer: AudioBuffer,
      speed = 1,
      offsetAmount = 0
    ): AudioBuffer {
      const clamp = (v: number, min: number, max: number) => Math.min(Math.max(v, min), max);
      const sampleOffset = Math.floor(clamp(offsetAmount, 0, 1) * buffer.length);
      const newLength = buffer.sampleRate * duration;
      const newBuffer = this.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate);
      
      for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
        const oldData = buffer.getChannelData(channel);
        const newData = newBuffer.getChannelData(channel);

        for (let i = 0; i < newLength; i++) {
          let position = (sampleOffset + i * Math.abs(speed)) % oldData.length;
          if (speed < 1) {
            position = position * -1;
          }
          newData[i] = oldData[Math.floor(position)] || 0;
        }
      }
      return newBuffer;
    };
    console.log('[audio-polyfill] Added AudioContext.prototype.adjustLength');
  }

  // Add createReverb method (from superdough/reverb.mjs)
  if (!AudioContext.prototype.createReverb) {
    AudioContext.prototype.createReverb = function(
      duration?: number,
      fade?: number,
      lp?: number,
      dim?: number,
      ir?: AudioBuffer,
      irspeed?: number,
      irbegin?: number
    ): ConvolverNode & { generate: Function; duration?: number; fade?: number; lp?: number; dim?: number; ir?: AudioBuffer; irspeed?: number; irbegin?: number } {
      const convolver = this.createConvolver() as ConvolverNode & {
        generate: Function;
        duration?: number;
        fade?: number;
        lp?: number;
        dim?: number;
        ir?: AudioBuffer;
        irspeed?: number;
        irbegin?: number;
      };
      
      const ctx = this;
      
      convolver.generate = function(
        d = 2,
        fadeIn = 0.1,
        lpFreq = 15000,
        dimFreq = 1000,
        irBuffer?: AudioBuffer,
        irSpeed?: number,
        irBegin?: number
      ) {
        convolver.duration = d;
        convolver.fade = fadeIn;
        convolver.lp = lpFreq;
        convolver.dim = dimFreq;
        convolver.ir = irBuffer;
        convolver.irspeed = irSpeed;
        convolver.irbegin = irBegin;
        
        if (irBuffer) {
          convolver.buffer = ctx.adjustLength(d, irBuffer, irSpeed, irBegin);
        } else {
          // Generate synthetic reverb impulse response
          // This is a simplified version - the original uses reverbGen.mjs
          const sampleRate = ctx.sampleRate;
          const length = Math.floor(sampleRate * d);
          const buffer = ctx.createBuffer(2, length, sampleRate);
          
          for (let channel = 0; channel < 2; channel++) {
            const data = buffer.getChannelData(channel);
            for (let i = 0; i < length; i++) {
              // Exponential decay with random noise
              const t = i / sampleRate;
              const decay = Math.exp(-3 * t / d);
              // Apply fade in
              const fadeEnv = t < fadeIn ? t / fadeIn : 1;
              data[i] = (Math.random() * 2 - 1) * decay * fadeEnv;
            }
          }
          
          // Apply simple lowpass filter effect by averaging nearby samples
          // (This is a very rough approximation of the original)
          if (lpFreq < 20000) {
            for (let channel = 0; channel < 2; channel++) {
              const data = buffer.getChannelData(channel);
              const filterStrength = Math.max(1, Math.floor(20000 / lpFreq));
              for (let i = filterStrength; i < length; i++) {
                let sum = 0;
                for (let j = 0; j < filterStrength; j++) {
                  sum += data[i - j];
                }
                data[i] = sum / filterStrength;
              }
            }
          }
          
          convolver.buffer = buffer;
        }
      };
      
      convolver.generate(duration, fade, lp, dim, ir, irspeed, irbegin);
      return convolver;
    };
    console.log('[audio-polyfill] Added AudioContext.prototype.createReverb');
  }

  // Initialize AudioWorklet polyfill for processors like shape, crush, etc.
  initWorkletPolyfill();

  // Wrap AudioWorkletNode to auto-disconnect nodes with 'end' parameter
  // This fixes the memory leak in superdough where LFO nodes for tremolo
  // are created but never disconnected (they're not added to the audioNodes array)
  // See: https://github.com/tidalcycles/strudel/issues/XXX (to be reported)
  //
  // The challenge: superdough's getWorklet() creates the node first, THEN sets parameters.
  // So we can't read 'end' at construction time. Instead, we defer the check using queueMicrotask.
  const OriginalAudioWorkletNode = (globalThis as any).AudioWorkletNode;
  if (OriginalAudioWorkletNode) {
    (globalThis as any).AudioWorkletNode = class AudioWorkletNodeWrapper extends OriginalAudioWorkletNode {
      constructor(context: AudioContext, name: string, options?: AudioWorkletNodeOptions) {
        super(context, name, options);
        
        // Check if this worklet has an 'end' parameter (like LFOProcessor)
        const endParam = this.parameters.get('end');
        if (endParam) {
          const node = this;
          const ctx = context;
          const nodeName = name;
          const createdAt = Date.now();
          
          // Defer the check to allow superdough's getWorklet() to set the parameters
          queueMicrotask(() => {
            const endTime = endParam.value;
            const currentTime = ctx.currentTime;
            
            // Track this node
            activeWorkletNodes.set(node, {
              node,
              name: nodeName,
              endTime,
              createdAt,
            });
            
            if (endTime > 0 && endTime > currentTime) {
              // Schedule disconnect slightly after end time (add 100ms buffer for processing)
              const delayMs = Math.max(0, (endTime - currentTime) * 1000 + 100);
              
              const timeout = setTimeout(() => {
                try {
                  node.disconnect();
                } catch {
                  // Already disconnected
                }
                scheduledDisconnects.delete(node);
                activeWorkletNodes.delete(node);
              }, delayMs);
              
              scheduledDisconnects.set(node, timeout);
            }
          });
        }
      }
    };
    console.log('[audio-polyfill] AudioWorkletNode wrapped for auto-disconnect (fixes tremolo leak)');
  }
}

/**
 * Load our Node.js-compatible worklets onto a specific audio context
 * Call this after superdough's audio context is available
 */
export async function loadNodeWorklets(ctx: any): Promise<void> {
  const path = await import('path');
  const { fileURLToPath } = await import('url');
  const __filename = fileURLToPath(import.meta.url);
  const __dirname = path.dirname(__filename);
  const workletPath = path.join(__dirname, 'worklets-node.js');
  
  console.log('[audio-polyfill] Loading Node.js worklets onto audio context...');
  try {
    await ctx.audioWorklet.addModule(workletPath);
    console.log('[audio-polyfill] Successfully loaded worklets-node.js');
  } catch (err) {
    console.error('[audio-polyfill] Failed to load worklets-node.js:', err);
    throw err;
  }
}

// Export the nodeWebAudio for convenience
export { nodeWebAudio };
